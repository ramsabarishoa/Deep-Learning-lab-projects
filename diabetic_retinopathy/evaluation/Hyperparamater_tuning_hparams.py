# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lA1An44QfUmM89hCUImMK5GwxtamPlOT
"""

import tensorflow as tf
import pandas as pd
import numpy as np
import zipfile
import glob, os
import sys
import matplotlib.pyplot as plt
print(tf.__version__)

import tensorflow.keras as k
from tensorflow import keras
from tensorflow.keras import layers 
from tensorflow.keras.models import Sequential
from keras.preprocessing import image
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import Activation, Flatten, Dense, Dropout

from tensorboard.plugins.hparams import api as hp

from google.colab import drive
drive.mount('/content/drive')

!unzip -uq "/content/drive/MyDrive/idrid.zip" -d "/content/drive/MyDrive"
print('Unzipped the contents to the drive')

batch_size = 32
img_ht = 256
img_wd = 256

pd.set_option('display.max_rows', 600)
pd.set_option('display.max_columns', None)
pd.set_option('display.width', 600)

np.set_printoptions(threshold=1000)

train_images = glob.glob("/content/drive/MyDrive/IDRID_dataset/images/train/*.jpg")
print('Total training images:',len(train_images))

df_train = pd.read_csv('/content/drive/MyDrive/IDRID_dataset/labels/train.csv')
df_train = df_train.drop_duplicates()
df_train = df_train.iloc[:, : 2]
#print(df_train)
print('Number of training samples:',len(df_train))
#df_train[['Retinopathy grade']].hist(figsize = (10, 5))
df_train['Retinopathy grade'] = df_train['Retinopathy grade'].replace([0,1,2,3,4],[0,0,1,1,1])
#df_train[['Retinopathy grade']].hist(figsize = (10, 5))
df_train = df_train.sample(frac=1).reset_index(drop=True)

N_Training = round(len(df_train) * 0.8)
print(N_Training)

train = df_train[:N_Training]
validation = df_train[N_Training:]
print('Number of training samples:',len(train))
print('Number of validation samples:',len(validation))

label_0 = train[train['Retinopathy grade'] == 0]
label_1 = train[train['Retinopathy grade'] == 1]
print('Label 0:',len(label_0),'\n','Label 1:',len(label_1))

label_count_1, label_count_0 = train['Retinopathy grade'].value_counts()
label_0 = label_0.sample(label_count_1,replace=True)
df_train_sampled = pd.concat([label_0,label_1])
df_train_sampled = df_train_sampled.sample(frac=1,random_state=0)
print(len(label_0),len(label_1))
#print(df_train_sampled)
#df_train_sampled[['Retinopathy grade']].hist(figsize = (10, 5))

df_train_sampled['Image name'] = df_train_sampled['Image name'] + '.jpg'
validation['Image name'] = validation['Image name'] + '.jpg'

images_list = []
labels_list = []
for iname,iclass in df_train_sampled.itertuples(index=False):
    for fp in train_images:
      if os.path.basename(fp) == iname:
        #print(fp,iname,iclass)
        images_list.append(fp)
        labels_list.append(iclass)

vimages_list = []
vlabels_list = []
for vname, vclass in validation.itertuples(index=False):
  for fv in train_images:
      if os.path.basename(fv) == vname:
        #print(fv,vname,vclass)
        vimages_list.append(fv)
        vlabels_list.append(vclass)

test_images = glob.glob("/content/drive/MyDrive/IDRID_dataset/images/test/*.jpg")
print(len(test_images))
df_test = pd.read_csv('/content/drive/MyDrive/IDRID_dataset/labels/test.csv')
df_test['Retinopathy grade'] = df_test['Retinopathy grade'].replace([0,1,2,3,4],[0,0,1,1,1])
df_test['Image name'] = df_test['Image name'] + '.jpg'
df_test = df_test.drop_duplicates()
df_test = df_test.iloc[:, : 2]
#print(df_test)

test_images_list = []
test_labels = []
for tname, tclass in df_test.itertuples(index=False):
  for ft in test_images:
    if os.path.basename(ft) == tname:
      #print(ft,tname,tclass)
      t_img = tf.io.read_file(ft)
      t_img_decoded = tf.io.decode_jpeg(t_img)

      t_img_cropped = tf.image.central_crop(t_img_decoded, central_fraction=0.95)
      t_img_cropped_bound = tf.image.crop_to_bounding_box(t_img_cropped, 0 , 0 , target_height = 2700, target_width = 3580)
      
      t_image_cast = tf.cast(t_img_cropped_bound, tf.float32) 
      t_image_cast = t_image_cast / 255.0
      t_image_resized = tf.image.resize(t_image_cast,size=(img_ht,img_wd))
      test_images_list.append(t_image_resized)
      test_labels.append(tclass)

print(len(images_list),len(labels_list))
print(len(vimages_list), len(vlabels_list))
print(len(test_images_list), len(test_labels))

images_list = tf.convert_to_tensor(images_list)
labels_list = tf.convert_to_tensor(labels_list)
vimages_list = tf.convert_to_tensor(vimages_list)
vlabels_list = tf.convert_to_tensor(vlabels_list)
test_images_list = tf.convert_to_tensor(test_images_list)
test_labels = tf.convert_to_tensor(test_labels)

def _parse_function(pimage, plabel,):
  img_train = tf.io.read_file(pimage)
  img_decoded = tf.io.decode_jpeg(img_train)

  img_cropped = tf.image.central_crop(img_decoded, central_fraction=0.95)
  img_cropped_bound = tf.image.crop_to_bounding_box(img_cropped, 0 , 0 , target_height = 2700, target_width = 3580)
  

  image_cast = tf.cast(img_cropped_bound, tf.float32) 
  image_cast = image_cast / 255.0
  image_resized = tf.image.resize(image_cast,size=(img_ht,img_wd))
  return image_resized, plabel

def build_dataset(a,b):
  AUTOTUNE = tf.data.experimental.AUTOTUNE
  dataset = tf.data.Dataset.from_tensor_slices((a,b))
  dataset = dataset.cache()
  dataset = dataset.map(_parse_function)
  dataset = dataset.batch(batch_size)
  dataset = dataset.prefetch(AUTOTUNE)
  return dataset

train_dataset = build_dataset(images_list, labels_list)
val_dataset = build_dataset(vimages_list,vlabels_list)


#Debug
print(tf.data.experimental.cardinality(train_dataset).numpy())
print(tf.data.experimental.cardinality(val_dataset).numpy())

for image, label in train_dataset.take(1):
  image_matrix = image.numpy()
  label_matrix = label.numpy()
  #image_matrix = image_matrix.astype('float32')
  #image_matrix = image_matrix / 255.0
  print(image_matrix.shape)
  print(label_matrix)

for image, label in val_dataset.take(1):
  image_matrix = image.numpy()
  label_matrix = label.numpy()
  print(image_matrix.shape)
  print(label_matrix)

#Debug
#Checking for the normalized values
image_batch, labels_batch = next(iter(train_dataset))
first_image = image_batch[0]
print(np.min(first_image), np.max(first_image))

image_batch, labels_batch = next(iter(val_dataset))
first_image = image_batch[0]
print(np.min(first_image), np.max(first_image))

#Printing the images
image_batch, labels_batch = next(iter(train_dataset))
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 5))
for i in range(9):
  ax = plt.subplot(3, 3, i + 1)
  plt.imshow(image_batch[i].numpy())
  label = labels_batch[i]
  plt.axis("off")

data_augmentation = keras.Sequential(
  [
    layers.experimental.preprocessing.RandomFlip("horizontal", input_shape=(img_ht, img_wd, 3)),
    layers.experimental.preprocessing.RandomRotation(0.02),
    layers.experimental.preprocessing.RandomZoom(0.02),
  ]
)

train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x), y))
image_batch, labels_batch = next(iter(train_dataset))
first_image = image_batch[0]
# Notice the pixels values are now in `[0,1]`.
print(np.min(first_image), np.max(first_image))

plt.figure(figsize=(10, 10))
for images, _ in train_dataset.take(1):
  for i in range(9):
    augmented_images = data_augmentation(images)
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(augmented_images[0].numpy())
    plt.axis("off")

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([128]))
HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.2,0.3, 0.4, 0.5]))
HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam']))
HP_EPOCHS = hp.HParam('epochs',hp.Discrete([50, 100]))

METRIC_ACCURACY = 'accuracy'

with tf.summary.create_file_writer('logs/hparam_tuning').as_default():
  hp.hparams_config(
      hparams = [HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER, HP_EPOCHS],
      metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],
  )

def train_test_model(hparams):
  model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256,256,3)),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),    
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),    
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),     
    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),            
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu),
    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),
    tf.keras.layers.Dense(2, activation=tf.nn.softmax),
  ])

  model.compile(
      optimizer=hparams[HP_OPTIMIZER],
      loss='sparse_categorical_crossentropy',
      metrics=['accuracy'],
  )
  model.fit(train_dataset, validation_data=val_dataset, epochs=hparams[HP_EPOCHS])

  
  _, accuracy = model.evaluate(test_images_list, test_labels)
  return accuracy

def run(run_dir, hparams):
  with tf.summary.create_file_writer(run_dir).as_default():
    hp.hparams(hparams)  # record the values used in this trial
    accuracy = train_test_model(hparams)
    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)

session_num = 0

for num_units in HP_NUM_UNITS.domain.values:
  for dropout_rate in HP_DROPOUT.domain.values:
    for optimizer in HP_OPTIMIZER.domain.values:
      for epochs in HP_EPOCHS.domain.values:

        hparams = {
            HP_NUM_UNITS: num_units,
            HP_DROPOUT: dropout_rate,
            HP_OPTIMIZER: optimizer,
            HP_EPOCHS: epochs,
        }
        run_name = "run-%d" % session_num
        print('--- Starting trial: %s' % run_name)
        print({h.name: hparams[h] for h in hparams})
        run('logs/hparam_tuning/' + run_name, hparams)
        session_num += 1

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs/hparam_tuning