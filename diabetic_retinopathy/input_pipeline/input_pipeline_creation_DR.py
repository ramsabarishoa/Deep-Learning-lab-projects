# -*- coding: utf-8 -*-
"""DRD_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16mrYhn7lNoHPmLrVVD_BWmK541eq9LGj
"""

# -*- coding: utf-8 -*-
"""Input_Pipeline_Creation_DR (1).ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1CPa_N0Uwb4IfsD6WMCasHu4kV79m_7nZ
''' Creation of an input pipeline for the IDRID dataset
Changes to be made according to your requirements is mentioned with '**TO_BE_CHANGED**' macro.
Please adapt it accordingly.
Folder structure of the dataset
    ROOT_FOLDER(/home/user/.../IDRID_dataset)
       |-------- images
       |            |------ train
       |            |           |------ IDRiD_001.jpg
       |            |                   etc...
       |            |------ test
       |                        |------ IDRiD_001.jpg
       |                                etc...
       |
       | -------- labels                 
       |             |
       |             | ----- test.csv
       |             | ----- train.csv
       |
    ```
'''
"""

#import necessary packages
import tensorflow as tf
import pandas as pd
import numpy as np
import zipfile
import glob, os
import sys
import matplotlib.pyplot as plt
print(tf.__version__)

import tensorflow.keras as k
from tensorflow import keras
from tensorflow.keras import layers 
from tensorflow.keras.models import Sequential
from keras.preprocessing import image
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import Activation, Flatten, Dense, Dropout

#TO_BE_CHANGED
#Mounting the contents to Google Drive
from google.colab import drive
drive.mount('/content/drive')

#Unzip the dataset to a path in the drive
!unzip -uq "/content/drive/MyDrive/idrid.zip" -d "/content/drive/MyDrive"
print('Unzipped the contents to the drive')

# Constants
batch_size = 32
img_ht = 256
img_wd = 256

pd.set_option('display.max_rows', 600)
pd.set_option('display.max_columns', None)
pd.set_option('display.width', 600)

np.set_printoptions(threshold=1000)

#TO_BE_CHANGED
#Load the train images

#Debug
#Decode a single image and print it

train_images = glob.glob("/content/drive/MyDrive/IDRID_dataset/images/train/*.jpg")
print('Total training images:',len(train_images))

eImg = tf.io.read_file(train_images[75])
eImg_decoded = tf.io.decode_jpeg(eImg)
tf.print('After decoding:',eImg_decoded.shape)

eImg_cropped = tf.image.central_crop(eImg_decoded, central_fraction=0.95)
eImg_cropped_bound = tf.image.crop_to_bounding_box(eImg_cropped, 0 , 0 , target_height = 2700, target_width = 3580)

eImg_flipped = tf.image.flip_left_right(eImg_cropped_bound)
eImg_saturated = tf.image.adjust_saturation(eImg_flipped, 3)

tf.print('After data augmentation:',eImg_saturated.shape)

eImg_cast = tf.cast(eImg_saturated,tf.float32) 
eImg_cast = eImg_cast / 255.0
#Resizing without distortion
eImg_resized = tf.image.resize_with_pad(eImg_cast,img_ht,img_wd,antialias=True)

tf.print('After resizing:',eImg_resized.shape)
plt.imshow(eImg_resized)
plt.show()

print('Normalization values:',np.min(eImg_resized), np.max(eImg_resized))

#TO_BE_CHANGED
# Loading the train.csv file
df_train = pd.read_csv('/content/drive/MyDrive/IDRID_dataset/labels/train.csv')
df_train = df_train.drop_duplicates()
df_train = df_train.iloc[:, : 2]

#Debug
#print(df_train)
#print(len(df_train))
#df_train[['Retinopathy grade']].hist(figsize = (10, 5))

"""Classifying the labels [0,1] to 0 and [2,3,4] to 1
NRDR is considered as having no or mild non-proliferative DR (labels 0 and 1). 
RDR is considered as having moderate, severe, or proliferative DR (labels 2 and up)."""

df_train['Retinopathy grade'] = df_train['Retinopathy grade'].replace([0,1,2,3,4],[0,0,1,1,1])

#Debug
#df_train[['Retinopathy grade']].hist(figsize = (10, 5))

label_0 = df_train[df_train['Retinopathy grade'] == 0]
label_1 = df_train[df_train['Retinopathy grade'] == 1]
print('Label 0:',len(label_0),'\n','Label 1:',len(label_1))

"""**Balancing the dataset**"""

label_count_1, label_count_0 = df_train['Retinopathy grade'].value_counts()
label_0 = label_0.sample(label_count_1,replace=True)
df_train_sampled = pd.concat([label_0,label_1])
df_train_sampled = df_train_sampled.sample(frac=1,random_state=0)
print(len(label_0),len(label_1))

#Debug
#print(df_train_sampled)
#df_train_sampled[['Retinopathy grade']].hist(figsize = (10, 5))

df_train_sampled['Image name'] = df_train_sampled['Image name'] + '.jpg'

#print(df_train_sampled)
images_list = []
labels_list = []
for iname,iclass in df_train_sampled.itertuples(index=False):
    for f in train_images:
      if os.path.basename(f) == iname:
        #print(file,iname,iclass)
        images_list.append(f)
        labels_list.append(iclass)

print(len(images_list),len(labels_list))
images_list = tf.constant(images_list)
labels_list = tf.constant(labels_list)

# A parser function to read an image from the set of images available and decode them further 
def _parse_function(pimage, plabel):
  img_train = tf.io.read_file(pimage)
  img_decoded = tf.io.decode_jpeg(img_train)

  img_cropped = tf.image.central_crop(img_decoded, central_fraction=0.95)
  img_cropped_bound = tf.image.crop_to_bounding_box(img_cropped, 0 , 0 , target_height = 2700, target_width = 3580)
  img_flipped = tf.image.flip_left_right(img_cropped_bound)
  img_saturated = tf.image.adjust_saturation(img_flipped, 3)

  image_cast = tf.cast(img_decoded, tf.float32) 
  image_cast = image_cast / 255.0
  image_resized = tf.image.resize(image_cast,size=(img_ht,img_wd))
  return image_resized, plabel

#Creating an input pipeline

def build_dataset(a,b):
  AUTOTUNE = tf.data.experimental.AUTOTUNE
  dataset = tf.data.Dataset.from_tensor_slices((a,b))
  dataset = dataset.cache()
  dataset = dataset.shuffle(batch_size)
  dataset = dataset.map(_parse_function)
  dataset = dataset.batch(batch_size)
  dataset = dataset.prefetch(AUTOTUNE)
  return dataset

N_training = round(len(df_train_sampled)*0.8)
N_validation = round(len(df_train_sampled)*0.2)

#print(N_training,N_validation)

train_dataset = build_dataset(images_list[0:N_training],labels_list[0:N_training])
val_dataset = build_dataset(images_list[N_training : N_training + N_validation],labels_list[N_training : N_training + N_validation])

#Debug
#print(tf.data.experimental.cardinality(train_dataset).numpy())
#print(tf.data.experimental.cardinality(val_dataset).numpy())


"""print('Number of elements in dataset:',len(list(dataset)))
plt.imshow(img.numpy())
plt.title(lbl.numpy())"""

for image, label in train_dataset.take(1):
  image_matrix = image.numpy()
  label_matrix = label.numpy()
  #image_matrix = image_matrix.astype('float32')
  #image_matrix = image_matrix / 255.0
  print(image_matrix.shape)
  print(label_matrix)

for image, label in val_dataset.take(1):
  image_matrix = image.numpy()
  label_matrix = label.numpy()
  print(image_matrix.shape)
  print(label_matrix)

#Debug
#Checking for the normalized values
"""image_batch, labels_batch = next(iter(train_dataset))
first_image = image_batch[0]
print(np.min(first_image), np.max(first_image))

image_batch, labels_batch = next(iter(val_dataset))
first_image = image_batch[0]
print(np.min(first_image), np.max(first_image))"""

#Printing the images
image_batch, labels_batch = next(iter(train_dataset))
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 5))
for i in range(9):
  ax = plt.subplot(3, 3, i + 1)
  plt.imshow(image_batch[i].numpy())
  label = labels_batch[i]
  plt.axis("off")