# -*- coding: utf-8 -*-
"""Input_Pipeline_Creation_DR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JNOHw2ATQ88L1II4R72phK_Ahx0ZhCk4
"""

''' Creation of an input pipeline for the IDRID dataset
Changes to be made according to your requirements is mentioned with '**TO_BE_CHANGED**' macro.
Please adapt it accordingly.
Folder structure of the dataset
    ROOT_FOLDER(/home/user/.../IDRID_dataset)
       |-------- images
       |            |------ train
       |            |           |------ IDRiD_001.jpg
       |            |                   etc...
       |            |------ test
       |                        |------ IDRiD_001.jpg
       |                                etc...
       |
       | -------- labels                 
       |             |
       |             | ----- test.csv
       |             | ----- train.csv
       |
    ```
'''

#import necessary packages
import tensorflow as tf
import pandas as pd
import numpy as np
import zipfile
import glob, os
import matplotlib.pyplot as plt
from PIL import Image
print(tf.__version__)

# Constants

BATCH_SIZE = 32
BASE_PATH = '/content/drive/MyDrive/IDRID_dataset'
img_height = 256
img_width = 256

#TO_BE_CHANGED
#Mounting the contents to Google Drive
from google.colab import drive
drive.mount('/content/drive')

#Unzip the dataset to a path in the drive
!unzip -uq "/content/drive/My Drive/idrid.zip" -d "/content/drive/My Drive/"
print('Unzipped the contents to the drive')

#TO_BE_CHANGED
#Load the images for training
train_images = glob.glob("/content/drive/MyDrive/IDRID_dataset/images/train/*.jpg")
print("Loaded training images")
#Read the CSV file containing the labels and images for training
#We have labels from 0 to 4 here
df_load_train_csv = pd.read_csv(BASE_PATH + '/labels/train.csv')
train_labels = (df_load_train_csv['Retinopathy grade'].values).tolist()

#Debug
#print(train_images,type(train_images),len(train_images))
#print(train_labels,type(train_labels),len(train_labels))

#TO_BE_CHANGED
#Load the test images
test_images = glob.glob("/content/drive/MyDrive/IDRID_dataset/images/test/*.jpg")
print("Loaded images for testing")
#Read the CSV file containing the labels and images for test

df_load_test_csv = pd.read_csv('/content/drive/MyDrive/IDRID_dataset/labels/test.csv')
test_labels = (df_load_test_csv['Retinopathy grade'].values).tolist()

#Debug
#print(test_images,type(test_images),len(test_images))
#print(test_labels,type(test_labels),len(test_labels))

#Debug
#Decode a single image and print it
train_ex_image = tf.io.read_file(train_images[0])
train_ex_image_decoded = tf.io.decode_jpeg(train_ex_image)
train_ex_cast = tf.cast(train_ex_image_decoded, tf.float32) / 255.
train_ex_resized = tf.image.resize(train_ex_cast,size=(img_height, img_width))
plt.imshow(train_ex_resized)
plt.show()

# A parser function to read an image from the set of images available and decode them further
def _parse_function(image_train,image_label):
  image_string = tf.io.read_file(image_train)
  image_decoded = tf.io.decode_jpeg(image_string)
  image_resized = tf.image.resize(image_decoded,size=(img_height, img_width))
  return image_decoded,image_label

# Creating a constant tensor by passing the train images and corresponding lables
filenames = tf.constant(train_images)
labels = tf.constant(train_labels)
#print(filenames,type(filenames),filenames.shape)
#print(labels,type(labels),labels.shape)

#Creating an input pipeline
dataset = tf.data.Dataset.from_tensor_slices((filenames,labels))
dataset = dataset.map(_parse_function)
dataset = dataset.shuffle(True)
dataset = dataset.batch(BATCH_SIZE)

img, lbl = next(iter(dataset))

for image,label in dataset.take(1):
  image_array = image.numpy()
  #Debug
  '''print(image_array.shape,label.shape)
  plt.subplot(title=label.numpy())
  plt.imshow(image_array)
  plt.show()'''

# Creating a validation set from the training images

no_of_val_images = int(0.2 * len(train_images))

validation_dataset = dataset.take(no_of_val_images)
print(len(validation_dataset),"Images for validation set")

for images, labels in validation_dataset.take(1):
  val_array = images.numpy()
  #Debug
  '''print(val_array.shape,label.shape)
  plt.subplot(title=label.numpy())
  plt.imshow(image_array)
  plt.show()'''
