# -*- coding: utf-8 -*-
"""Input_Pipeline_Creation_DR (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CPa_N0Uwb4IfsD6WMCasHu4kV79m_7nZ

''' Creation of an input pipeline for the IDRID dataset
Changes to be made according to your requirements is mentioned with '**TO_BE_CHANGED**' macro.
Please adapt it accordingly.
Folder structure of the dataset
    ROOT_FOLDER(/home/user/.../IDRID_dataset)
       |-------- images
       |            |------ train
       |            |           |------ IDRiD_001.jpg
       |            |                   etc...
       |            |------ test
       |                        |------ IDRiD_001.jpg
       |                                etc...
       |
       | -------- labels                 
       |             |
       |             | ----- test.csv
       |             | ----- train.csv
       |
    ```
'''
"""

#import necessary packages
import tensorflow as tf
import pandas as pd
import numpy as np
import zipfile
import glob, os
import matplotlib.pyplot as plt
from keras.preprocessing import image
print(tf.__version__)

# Constants
BATCH_SIZE = 32
BASE_PATH = '/content/drive/MyDrive/IDRID_dataset'
img_height = 256
img_width = 256

#TO_BE_CHANGED
#Mounting the contents to Google Drive
from google.colab import drive
drive.mount('/content/drive')

#Unzip the dataset to a path in the drive
!unzip -uq "/content/drive/MyDrive/idrid.zip" -d "/content/drive/MyDrive"
print('Unzipped the contents to the drive')

#TO_BE_CHANGED
#Load the images for training
train_images = glob.glob("/content/drive/MyDrive/IDRID_dataset/images/train/*.jpg")
print("Loading train images")
#Read the CSV file containing the labels and images for training
#We have labels from 0 to 4 here

#Debug
#print(train_images,type(train_images),len(train_images))
#print(train_labels,type(train_labels),len(train_labels))

#Debug
#Decode a single image and print it
train_ex_image = tf.io.read_file(train_images[10])
train_ex_image_decoded = tf.io.decode_jpeg(train_ex_image)
print(train_ex_image_decoded.shape.as_list())
train_ex_cast = tf.cast(train_ex_image_decoded, tf.float32) / 255
train_ex_resized = tf.image.resize(train_ex_cast,size=(img_height, img_width)).shape.as_list()
print(train_ex_resized)
#Resizing without distortion
train_ex_resized = tf.image.resize_with_pad(train_ex_cast,256,256,antialias=True)

plt.imshow(train_ex_resized)
plt.show()

df_load_train_csv = pd.read_csv(BASE_PATH + '/labels/train.csv')
df_load_train_csv[['Retinopathy grade']].hist(figsize = (10, 5))

#TO_BE_CHANGED
#Load the test images
test_images = glob.glob("/content/drive/MyDrive/IDRID_dataset/images/test/*.jpg")
print("Loaded images for testing")
#Read the CSV file containing the labels and images for test

df_load_test_csv = pd.read_csv('/content/drive/MyDrive/IDRID_dataset/labels/test.csv')
test_labels = (df_load_test_csv['Retinopathy grade'].values).tolist()

#Debug
#print(test_images,type(test_images),len(test_images))
#print(test_labels,type(test_labels),len(test_labels))

"""**Balancing the dataset**"""

"""Classifying the labels [0,1] to 0 and [2,3,4] to 1
NRDR is considered as having no or mild non-proliferative DR (labels 0 and 1). 
RDR is considered as having moderate, severe, or proliferative DR (labels 2 and up)."""

df_load_train_csv = pd.read_csv(BASE_PATH + '/labels/train.csv')
df_load_train_csv = df_load_train_csv[['Image name','Retinopathy grade']].drop_duplicates()

df_load_train_csv['Retinopathy grade'] = df_load_train_csv['Retinopathy grade'].replace([0,1,2,3,4],[0,0,1,1,1])
#df_load_train_csv[['Retinopathy grade']].hist(figsize = (10,5))

class_count_1, class_count_0 = df_load_train_csv['Retinopathy grade'].value_counts()
class_0 = df_load_train_csv[df_load_train_csv['Retinopathy grade'] == 0 ]
class_1 = df_load_train_csv[df_load_train_csv['Retinopathy grade'] == 1 ]
#print(df_load_train_csv)
#print(class_count_0,class_count_1)
print('Before resampling class 0:', class_0.shape)
print('Before resampling class 1:', class_1.shape)
"""pd.set_option('display.max_rows', 600)
pd.set_option('display.max_columns', 600)
pd.set_option('display.width', 1000)"""

class_0_over = class_0.sample(class_count_1,replace=True)
#print(class_0_over)
concat_class = pd.concat([class_0_over, class_1], axis=0)
#print(concat_class)

concat_class['Retinopathy grade'].hist(figsize = (10, 5))
class_count_1_resampled, class_count_0_resampled = concat_class['Retinopathy grade'].value_counts()
class_count_0_resampled = concat_class[concat_class['Retinopathy grade'] == 0]
class_count_1_resampled = concat_class[concat_class['Retinopathy grade'] == 1]
print('After resampling class 0:',class_count_0_resampled.shape)
print('After resampling class 1:',class_count_1_resampled.shape)

train_list = []
count = 0
for file in glob.glob('/content/drive/MyDrive/IDRID_dataset/images/train/*.jpg'):
  file = os.path.basename(file)
  for column_values in concat_class['Image name']:
    column_values = column_values + '.jpg'
    if column_values in file:
      file_path = '/content/drive/MyDrive/IDRID_dataset/images/train/' + file
      train_list.append(file_path)

# A parser function to read an image from the set of images available and decode them further 
def _parse_function(image_train,labels):
  image_string = tf.io.read_file(image_train)
  image_decoded = tf.io.decode_jpeg(image_string)
  image_cast = tf.cast(image_decoded, tf.float32) / 255
  #image_resized = tf.image.resize(image_decoded,size=(img_height, img_width))
  image_resized = tf.image.resize_with_pad(image_cast,256,256)
  return image_resized,labels

# Creating a constant tensor by passing the train images and corresponding lables
filenames = tf.constant(train_list)
labels = tf.constant(concat_class['Retinopathy grade'])
#print(filenames,type(filenames),filenames.shapprint(labels,type(labels),labels.shape)

N_training_examples = 518
N_validation_examples = int(0.2*N_training_examples)

#Creating an input pipeline

dataset = tf.data.Dataset.from_tensor_slices((filenames,labels))
dataset = dataset.shuffle(BATCH_SIZE)
dataset = dataset.map(_parse_function)
dataset = dataset.batch(BATCH_SIZE)

train_dataset = dataset.take(N_training_examples).shuffle(True)
validation_dataset = dataset.take(N_validation_examples).shuffle(True)

"""for image_batch, labels_batch in train_dataset:
  print(image_batch.shape)
  print(labels_batch.shape)
  break

for image_batch, labels_batch in validation_dataset:
  print(image_batch.shape)
  print(labels_batch.shape)
  break"""

AUTOTUNE = tf.data.experimental.AUTOTUNE

train_dataset = train_dataset.cache().shuffle(True).prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)

"""for image_batch, labels_batch in train_dataset:
  print(image_batch.shape)
  print(labels_batch.shape)
  break

for image_batch, labels_batch in validation_dataset:
  print(image_batch.shape)
  print(labels_batch.shape)
  break"""